{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are creating a dataset which is based on all of the dual-task trials per block and we are ignoring the practice trials\n",
    "# The dataset is built by merging the results acquired in the paper created by Chris (---link---)\n",
    "\n",
    "# Some columns are based on the significance provided in the said paper ( & maybe image here)\n",
    "# The csv files we are merging into our dataset are provided below\n",
    "\n",
    "# -MaxDeviationPerTrial.csv\n",
    "# -maxnrDigitEnteredPerPPAndPerBlockPerTrial.csv\n",
    "# -numberOfVisitsTrackerPerParticipantPerBlock.csv (trial data)\n",
    "# samplesOutsideTrial.csv(*)\n",
    "# sdVisTime.csv(*)\n",
    "# tableForMeanTimeInDigitPerPPandPerBlock.csv(*) - merge the data ber block maybe?\n",
    "\n",
    "# We are using the payoff function values provided in the meanVisTime.csv file\n",
    "# The columns marked with star could be significant and we are testing to see the results with or without the said feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loaded data!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We first read the data and display it\n",
    "final_rows = []\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('./data.csv');\n",
    "\n",
    "display('loaded data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulting length : 8\n"
     ]
    }
   ],
   "source": [
    "# We first split the data into 8 datasets\n",
    "# and we calculate the mean value for each of the dataset\n",
    "# in order to see how biased the data is in terms of \n",
    "# Radius, Noise and the payoff function\n",
    "\n",
    "split_on = ['PayOffFunctionNumeric','Radius','Noise']\n",
    "\n",
    "def split(dataSets,col):\n",
    "    \n",
    "    s = []\n",
    "    \n",
    "    for data in dataSets:\n",
    "        \n",
    "        if(col >= len(split_on)):\n",
    "            return None\n",
    "        \n",
    "        values = {}\n",
    "        \n",
    "        for row in range(0,data.shape[ 0 ]):\n",
    "            splitColumn = split_on[ col ]\n",
    "\n",
    "            rowValue = data.iloc[ row ][ splitColumn ]\n",
    "            \n",
    "            if not rowValue in values:\n",
    "                values[ rowValue ] = [ ]\n",
    "                \n",
    "            values[ rowValue ].append(row)\n",
    "            \n",
    "        for value in values:\n",
    "            \n",
    "            nextSet = []\n",
    "            \n",
    "            for row in values[value]:\n",
    "                nextSet.append(data.iloc[ row ])\n",
    "                \n",
    "            s.append(pd.DataFrame(nextSet))\n",
    "            \n",
    "        \n",
    "    res = split( s , col + 1 )\n",
    "    \n",
    "    if res is None:\n",
    "        return s\n",
    "    else: \n",
    "        return res\n",
    "    \n",
    "sets = [ data ]\n",
    "\n",
    "split_sets = split(sets,0)\n",
    "\n",
    "print('resulting length : ' +  str(len(split_sets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We then take the top N percent of each of the sets\n",
    "\n",
    "def get_by_split(sets,start, step, end, func):\n",
    "    \n",
    "    while start <= end:\n",
    "        \n",
    "        for dataSet in sets:\n",
    "            \n",
    "            sorted_set = dataSet.sort_values('Score',ascending=[False])\n",
    "            func(start,sorted_set)\n",
    "            \n",
    "        start = start + step\n",
    "\n",
    "per_tick = {}\n",
    "\n",
    "#we save all of the datasets in this variable for later use\n",
    "datasets = []\n",
    "\n",
    "#We then compute the mean for the score column for the provided dataset\n",
    "def mean(current_tick,item):\n",
    "\n",
    "    meanVal = item['Score'].mean()\n",
    "    \n",
    "    if current_tick not in per_tick:\n",
    "        per_tick[current_tick]= []\n",
    "        \n",
    "    per_tick[current_tick].append(meanVal)\n",
    "    datasets.append(item)\n",
    "\n",
    "get_by_split(split_sets, 1, 0.05, 1,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfL/VtzyegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25ec902d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can now measure the distributions\n",
    "# by testing different sizes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for tick_size in per_tick:\n",
    "    tick_marks = np.arange(len(per_tick[tick_size]))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(tick_marks,per_tick[tick_size])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "i = 0;\n",
    "perc = 10\n",
    "\n",
    "while(i <= 9):\n",
    "    conc = []\n",
    "    \n",
    "    #Here might be some missing one from rounding,\n",
    "    #TODO: check if it's correct\n",
    "    \n",
    "    for dataSet in datasets:\n",
    "        size = int(dataSet.shape[0] / perc)\n",
    "        take = i * perc\n",
    "        next_items = dataSet[take:take+size]\n",
    "        conc.append(next_items)\n",
    "        \n",
    "    if i not in dictionary:\n",
    "        dictionary[i]= []\n",
    "        \n",
    "    dictionary[i].append(conc)\n",
    "    i = i + 1\n",
    "    \n",
    "frames = []\n",
    "\n",
    "for key in dictionary:\n",
    "    df = pd.DataFrame()\n",
    "    for item in dictionary[key]:\n",
    "        df.append(item)\n",
    "    frames.append(df)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X shape : (1440, 12)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Y shape : (1440,)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Finished train test split'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then we split the data into training and testing sets by using the train test split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Percentage of \n",
    "test = 0.25\n",
    "\n",
    "y = data[ 'Score' ]\n",
    "X = data.drop( 'Score',1 )\n",
    "\n",
    "#We split the data in train and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test)\n",
    "\n",
    "display('X shape : ' + str(X_train.shape))\n",
    "display('Y shape : ' + str(y_train.shape))\n",
    "\n",
    "display('Finished train test split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized algorithms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import tree\n",
    "\n",
    "# here be les dragons\n",
    "sv = SVR()\n",
    "tr = tree.DecisionTreeRegressor()\n",
    "\n",
    "print('Initialized algorithms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using grid search CV to tweak parameters\n",
    "# We define a hyper parameter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dict_grid = {\n",
    "    sv: [\n",
    "            {\n",
    "                'C': [1, 10, 100, 1000], \n",
    "                'kernel' : ['linear']\n",
    "            },\n",
    "            {\n",
    "                'C': [1, 10, 100, 1000], \n",
    "                'gamma': [0.001, 0.0001], \n",
    "                'kernel': ['rbf']\n",
    "            }\n",
    "    ],\n",
    "    tr : [\n",
    "            {\n",
    "                #TODO:...\n",
    "            }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-fe6eb7740c7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0malgorithms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sv' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "algorithms = [sv,tr]\n",
    "scores = ['r2']\n",
    "\n",
    "print('...shuffling ...')\n",
    "\n",
    "X_shuff = shuffle( X_train )\n",
    "\n",
    "print( '...finished shuffling... ' )\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    display(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    \n",
    "    for algorithm in algorithms:\n",
    "        \n",
    "        display( '-------- Starting a new grid search CV fitting with model --------' )\n",
    "        display( 'Fitting with model : ' + str(algorithm) )\n",
    "        \n",
    "        clf = GridSearchCV(algorithm, dict_grid[algorithm], scoring = '%s' % score)\n",
    "        clf.fit( X_train, y_train )\n",
    "        \n",
    "display('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
