{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We are creating a dataset which is based on all of the dual-task trials per block and we are ignoring the practice trials\n",
    "The dataset is built by merging the results acquired in the paper created by Chris.\n",
    "\n",
    "Some columns are based on the significance provided in the said paper ( & maybe image here)\n",
    "The csv files we are merging into our dataset are provided below\n",
    "\n",
    "- MaxDeviationPerTrial.csv\n",
    "- maxnrDigitEnteredPerPPAndPerBlockPerTrial.csv\n",
    "- numberOfVisitsTrackerPerParticipantPerBlock.csv (trial data)\n",
    "- samplesOutsideTrial.csv(*)\n",
    "- sdVisTime.csv(*)\n",
    "- tableForMeanTimeInDigitPerPPandPerBlock.csv(*) - merge the data ber block maybe?\n",
    "- We are using the payoff function values provided in the meanVisTime.csv file\n",
    "- The columns marked with star could be significant and we are testing to see the results with or without the said feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Loaded the data!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We first read the data and display it\n",
    "final_rows = []\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('./data.csv');\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "display('Loaded the data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split the data into 8 data sets\n",
    "We first split the data into 8 datasets and we calculate the mean value for each of the datasetin order to see how biased the data is in terms of Radius, Noise and the payoff function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulting length : 8\n"
     ]
    }
   ],
   "source": [
    "split_on = ['PayOffFunction','Radius','Noise']\n",
    "\n",
    "def split(dataSets,col):\n",
    "    \n",
    "    s = []\n",
    "    \n",
    "    for data in dataSets:\n",
    "        \n",
    "        if(col >= len(split_on)):\n",
    "            return None\n",
    "        \n",
    "        values = {}\n",
    "        \n",
    "        for row in range(0,data.shape[ 0 ]):\n",
    "            splitColumn = split_on[ col ]\n",
    "\n",
    "            rowValue = data.iloc[ row ][ splitColumn ]\n",
    "            \n",
    "            if not rowValue in values:\n",
    "                values[ rowValue ] = [ ]\n",
    "                \n",
    "            values[ rowValue ].append(row)\n",
    "            \n",
    "        for value in values:\n",
    "            nextSet = []\n",
    "            \n",
    "            for row in values[value]:\n",
    "                nextSet.append(data.iloc[ row ])\n",
    "                \n",
    "            s.append(pd.DataFrame(nextSet))\n",
    "    res = split( s , col + 1 )\n",
    "    \n",
    "    if res is None:\n",
    "        return s\n",
    "    else: \n",
    "        return res\n",
    "    \n",
    "sets = [ data ]\n",
    "\n",
    "split_sets = split(sets,0)\n",
    "\n",
    "#for debug\n",
    "#i = 0\n",
    "#for item in split_sets:\n",
    "#    item.to_csv('dataset_' + str(i) + '.csv')\n",
    "#    i = i + 1\n",
    "\n",
    "print('resulting length : ' +  str(len(split_sets)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#We then take the top N percent of each of the sets\n",
    "\n",
    "def get_by_split(sets,start, step, end, func):\n",
    "    \n",
    "    while start <= end:\n",
    "    \n",
    "        for dataSet in sets:\n",
    "            func(start,dataSet)\n",
    "            \n",
    "        start = start + step\n",
    "\n",
    "per_tick = {}\n",
    "\n",
    "#we save all of the datasets in this variable for later use\n",
    "datasets = []\n",
    "\n",
    "#We then compute the mean for the score column for the provided dataset\n",
    "def mean(current_tick,item):\n",
    "\n",
    "    #meanVal = item['Score'].mean()\n",
    "    \n",
    "    #if current_tick not in per_tick:\n",
    "    #    per_tick[current_tick]= []\n",
    "   #     \n",
    "   # per_tick[current_tick].append(meanVal)\n",
    "    datasets.append(item)\n",
    "\n",
    "get_by_split(split_sets, 1, 0.05, 1,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "d = []\n",
    "for dataset in datasets:\n",
    "    newset = shuffle(dataset)\n",
    "    d.append(newset)\n",
    "datasets = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. For each of the produced datasets we can now compute different statististics.\n",
    "Currently we are computing and plotting the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can now measure the distributions\n",
    "# by testing different sizes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "for tick_size in per_tick:\n",
    "    tick_marks = np.arange(len(per_tick[tick_size]))\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(tick_marks,per_tick[tick_size])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 8 datasets\n",
      "starting to aquire chunk 0\n",
      "starting to aquire chunk 1\n",
      "starting to aquire chunk 2\n",
      "starting to aquire chunk 3\n",
      "starting to aquire chunk 4\n",
      "starting to aquire chunk 5\n",
      "starting to aquire chunk 6\n",
      "starting to aquire chunk 7\n",
      "starting to aquire chunk 8\n",
      "starting to aquire chunk 9\n",
      "done partitioning in chunks\n"
     ]
    }
   ],
   "source": [
    "dictionary = {}\n",
    "\n",
    "i = 0;\n",
    "perc = 10\n",
    "rowCounter = 0\n",
    "\n",
    "print( 'there are ' + str(len(datasets)) + ' datasets' )\n",
    "\n",
    "while(i <= 9):\n",
    "    \n",
    "    print('starting to aquire chunk ' + str(i))\n",
    "    \n",
    "    rp = []\n",
    "\n",
    "    for next_set in datasets:\n",
    "        size = int(next_set.shape[0] / perc)\n",
    "        \n",
    "        #starting point\n",
    "        take = i * size\n",
    "        start = take\n",
    "        end = take + size\n",
    "        next_items = next_set[start:end]\n",
    "        \n",
    "        frame = pd.DataFrame(next_items,columns=next_set.columns)\n",
    "        rp.append(frame)\n",
    "        \n",
    "    dictionary[ i ] = pd.concat(shuffle(rp))\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "print('done partitioning in chunks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Then we split the data by using cross-sampling and we use cross-validation\n",
    "\n",
    "The idea behind this is that we want to have equal distribution of the data in order to avoid the model becoming biased towards certain characteristics. We also remove some of the columns that are not neccessary when training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "\n",
    "def cross_validate(func, label, ignore_columns):\n",
    " splits = {}\n",
    " k = 0\n",
    " \n",
    " best_score = -999999\n",
    " model_y = None\n",
    " ordered_dataset = None\n",
    " print('Begin training classifier')\n",
    "\n",
    " for k in dictionary:\n",
    "     test_set = dictionary[k]\n",
    "     train_q = [test_set]\n",
    "    \n",
    "     for key in dictionary:\n",
    "         if key == k: \n",
    "             continue\n",
    "         train_q.append(dictionary[key])\n",
    "        \n",
    "     train_data = pd.concat(train_q)\n",
    "     re_insert = []\n",
    "    \n",
    "     for i in ignore_columns:\n",
    "        re_insert.append(train_data[i])\n",
    "        train_data = train_data.drop(i,1)\n",
    "        \n",
    "        \n",
    "     y = train_data[ label ]\n",
    "     X = train_data.drop( label , 1 )\n",
    "        \n",
    "     indic = []\n",
    "    \n",
    "     for i in range(0, X.shape[0]):\n",
    "        if i < test_set.shape[0]:\n",
    "            indic.append(1)\n",
    "        else:\n",
    "            indic.append(-1)\n",
    "                \n",
    "     #https://stackoverflow.com/questions/31948879/using-explict-predefined-validation-set-for-grid-search-with-sklearn\n",
    "     ps = PredefinedSplit(test_fold=indic)\n",
    "        \n",
    "     result = func(X,y,ps)\n",
    "    \n",
    "     if result[0] > best_score:\n",
    "            \n",
    "        best_score=result[0]\n",
    "        ordered_dataset = result[2]\n",
    "        model_y=result[1]\n",
    "        \n",
    "        ordered_dataset['distance_to_hyperplane'] = model_y\n",
    "        ordered_dataset[label] = y\n",
    "        \n",
    "        ordered_dataset['prediction'] = result[3]\n",
    "        items = []\n",
    "        \n",
    "        for i in range(0,X.shape[0]):\n",
    "            if i < test_set.shape[0]:\n",
    "                items.append(True)\n",
    "            else:\n",
    "                items.append(False)\n",
    "                \n",
    "        ordered_dataset['is_test']=items\n",
    " \n",
    " print('End training classifier')\n",
    "    \n",
    " print('Avg speed')\n",
    " speed = ordered_dataset.loc[ordered_dataset['PayOffFunction'] == 'Speed']['d'].mean()\n",
    " acc = ordered_dataset.loc[ordered_dataset['PayOffFunction'] == 'Accuracy']['d'].mean()\n",
    "\n",
    " print(speed)\n",
    " print('Avg acc')\n",
    "\n",
    " print(acc)\n",
    " return ordered_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a support vector classifier and initialize\n",
    "\n",
    "We also create a grid which is used to search for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sv = SVC(cache_size=7000)\n",
    "# Using grid search CV to tweak parameters\n",
    "# We define a hyper parameter\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dict_grid = {\n",
    "    sv: [\n",
    "            {\n",
    "                'C': [10,100,1000], \n",
    "                'gamma' : [1,10],\n",
    "                'kernel' : ['linear','rbf']\n",
    "            }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. We train the model using the provided grid\n",
    "\n",
    "After the training is finished and we compute the distance to the hyperplane and the classification results for all of the data.\n",
    "We are using the accuracy score to rate the quality of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X,y,fold):\n",
    "    \n",
    " best_model = None\n",
    " best_score = -999999\n",
    " predictions = None\n",
    " algorithms = [sv]\n",
    " scores = ['accuracy']\n",
    "    \n",
    " for score in scores:\n",
    "    for algorithm in algorithms:\n",
    "        display('Training started')\n",
    "        grid = dict_grid[algorithm]\n",
    "        clf = GridSearchCV(algorithm,grid , scoring = '%s' % score, cv = fold)\n",
    "        \n",
    "        clf.fit( X, y )\n",
    "        \n",
    "        #In short when using a linear kernel, the result is a hyperplane and it's parameters\n",
    "        # are present in the weights & intercept properties of the clf object.\n",
    "\n",
    "        print('score : ' + str(clf.best_score_))\n",
    "        \n",
    "        if(clf.best_score_ > best_score):\n",
    "            best_model = clf\n",
    "            best_score = clf.best_score_\n",
    "            predictions = clf.predict(X)\n",
    " display('Training finished')\n",
    "            \n",
    " return (best_score, best_model.decision_function(X), X, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execute all the operations and export the results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training classifier\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training started'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from  matplotlib import pyplot\n",
    "\n",
    "import seaborn\n",
    "seaborn.set(style='ticks')\n",
    "\n",
    "\n",
    "\n",
    "augmented_dataset = cross_validate( train_model, 'PayOffFunction', ['TrialNumber'])\n",
    "\n",
    "augmented_dataset.head(5).columns\n",
    "\n",
    "augmented_dataset.to_csv('result.csv')\n",
    "\n",
    "#index in the initial dataset\n",
    "augmented_dataset['index'] = augmented_dataset.index\n",
    "\n",
    "fg = seaborn.FacetGrid(data=augmented_dataset, hue='PayOffFunction', aspect=1.61)\n",
    "fg.map(pyplot.scatter, 'index', 'distance').add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
